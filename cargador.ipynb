{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdff7269-a193-4599-a4d5-713bf17ffee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos librerias varias\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "from pandas_ods_reader import read_ods\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c714b28c-43be-42b3-b639-41bae6d96e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacemos una lista con los archivos\n",
    "archivos = glob.glob('*.ods')\n",
    "# imprimimos la lista para ver si esta bien\n",
    "# archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3676e4a8-1142-40f6-aacc-ffec2360b049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.44 s, sys: 2.01 s, total: 6.46 s\n",
      "Wall time: 34min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# envolvemos la lectura del ods en una funcion\n",
    "def read_ods_sal(nombre):\n",
    "    # lee el achivo/hoja en un dataframe\n",
    "    return pd.read_excel(nombre, engine='odf', skiprows=10, sheet_name='Salientes')\n",
    "\n",
    "def proceso_sal():\n",
    "    # hacemos una lista con los archivos\n",
    "    archivos = glob.glob('*.ods')\n",
    "    # Armamos un pool con 4 nucleos\n",
    "    with Pool(processes=8) as pool: \n",
    "        # hacemos que mapee la funcion a los archivos\n",
    "        df_temp = pool.map(read_ods_sal, archivos)\n",
    "        # reducimos concatenando las partes\n",
    "        salientes = pd.concat(df_temp, ignore_index=True)\n",
    "    salientes.to_pickle('./salientes.pkl')\n",
    "\n",
    "proceso_sal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e5a45db-4323-4f37-b465-28514188669a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'salientes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msalientes\u001b[49m\u001b[38;5;241m.\u001b[39mto_pickle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./salientes.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'salientes' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# envolvemos la lectura del ods en una funcion\n",
    "def read_ods_ent(nombre):\n",
    "    # lee el achivo/hoja en un dataframe\n",
    "    return pd.read_excel(nombre, engine='odf', skiprows=10, sheet_name='Entrantes')\n",
    "\n",
    "def proceso_ent():\n",
    "    # hacemos una lista con los archivos\n",
    "    archivos = glob.glob('*.ods')\n",
    "    # Armamos un pool con 4 nucleos\n",
    "    with Pool(processes=8) as pool: \n",
    "        # hacemos que mapee la funcion a los archivos\n",
    "        df_temp = pool.map(read_ods_ent, archivos)\n",
    "        # reducimos concatenando las partes\n",
    "        entrantes = pd.concat(df_temp, ignore_index=True)\n",
    "    entrantes.to_pickle('./salientes.pkl')\n",
    "\n",
    "proceso_ent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7d7031-b9fb-4a01-bc79-7a526d48e202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARCHIVO 12.ods\n",
      "ARCHVIO 32.ods\n",
      "ARCHIVO 34.ods\n",
      "ARCHIVO 23.ods\n",
      "ARCHIVO 38.ods\n",
      "ARCHIVO 8.ods\n",
      "ARCHIVO 10.ods\n",
      "ARCHIVO 16.ods\n",
      "ARCHIVO 36.ods\n",
      "ARCHIVO 11.ods\n",
      "ARCHIVO 41.ods\n",
      "ARCHIVO 39.ods\n",
      "ARCHIVO 15.ods\n",
      "ARCHIVO 7.ods\n",
      "ARCHIVO 1.ods\n",
      "ARCHIVO 5.ods\n"
     ]
    }
   ],
   "source": [
    "# Hacemos dos dataframes vacios\n",
    "salientes = pd.DataFrame()\n",
    "entrantes = pd.DataFrame()\n",
    "\n",
    "# recorremos todos los archivos en un loop\n",
    "for archivo in archivos:\n",
    "    temporal = pd.read_excel(archivo, engine='odf', skiprows=10, sheet_name='Salientes')\n",
    "    salientes = pd.concat([salientes, temporal])\n",
    "    temporal = pd.read_excel(archivo, engine='odf', skiprows=10, sheet_name='Entrantes')\n",
    "    entrantes = pd.concat([entrantes, temporal])\n",
    "    print(archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ae240a-77eb-4058-9d37-fd8f142613e0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#entrantes.to_pickle('./entrantes.pkl')\n",
    "salientes.to_pickle('./salientes.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
